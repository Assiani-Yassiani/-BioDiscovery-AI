"""
ü§ñ DATA COLLECT - Orchestrateur Principal
==========================================
Coordonne tous les robots de collecte de donn√©es

UTILISATION:
-----------
python data_collect.py --query "BRCA1 breast cancer" --all
python data_collect.py --query "TP53 p53 cancer" --papers --sequences
python data_collect.py --query "Alzheimer tau protein" --max 50

ROBOTS DISPONIBLES:
------------------
- papers: Articles PubMed (ArticleDocument)
- images: Pathways KEGG (ImageDocument)
- experiments: Datasets GEO (ExperimentDocument)
- sequences: Prot√©ines UniProt (ProteinDocument)
- structures: Structures 3D PDB (StructureDocument)
"""

import argparse
import os
import json
from datetime import datetime
from typing import List

from robots import (
    RobotPapers,
    RobotImages,
    RobotExperiments,
    RobotSequences,
    RobotStructures
)


# ============================================================================
# CONFIGURATION
# ============================================================================

BASE_DIR = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))
DATA_DIR = os.path.join(BASE_DIR, "data")


def setup_directories():
    """Cr√©e la structure de dossiers"""
    os.makedirs(DATA_DIR, exist_ok=True)
    print(f"üìÅ Dossier de donn√©es: {DATA_DIR}")


def extract_genes_and_keywords(query: str) -> tuple:
    """
    Extrait les g√®nes et mots-cl√©s d'une requ√™te
    
    Returns:
        (genes, keywords, organism)
    """
    import re
    
    # G√®nes communs
    common_genes = {
        "BRCA1", "BRCA2", "TP53", "P53", "KRAS", "EGFR", 
        "BRAF", "PTEN", "AKT1", "MYC", "BCL2", "VEGF",
        "APP", "MAPT", "TAU", "SNCA", "HTT"
    }
    
    # Mots-cl√©s maladies
    disease_keywords = {
        "cancer", "tumor", "carcinoma", "leukemia", "lymphoma",
        "alzheimer", "parkinson", "diabetes", "disease",
        "breast", "lung", "prostate", "colon", "ovarian"
    }
    
    # Organisme
    organism = "Homo sapiens"  # d√©faut
    if "mouse" in query.lower():
        organism = "Mus musculus"
    elif "rat" in query.lower():
        organism = "Rattus norvegicus"
    
    # Extraire g√®nes
    query_upper = query.upper()
    genes = [g for g in common_genes if g in query_upper]
    
    # Extraire keywords
    query_lower = query.lower()
    keywords = [kw for kw in disease_keywords if kw in query_lower]
    
    return genes, keywords, organism


# ============================================================================
# ORCHESTRATEUR PRINCIPAL
# ============================================================================

class DataCollector:
    """
    Orchestrateur principal qui coordonne tous les robots
    """
    
    def __init__(self):
        setup_directories()
        
        # Initialiser tous les robots
        self.robot_papers = RobotPapers(DATA_DIR)
        self.robot_images = RobotImages(DATA_DIR)
        self.robot_experiments = RobotExperiments(DATA_DIR)
        self.robot_sequences = RobotSequences(DATA_DIR)
        self.robot_structures = RobotStructures(DATA_DIR)
        
        print("\n" + "="*70)
        print("ü§ñ DATA COLLECTOR - Syst√®me de collecte automatique")
        print("="*70)
    
    
    def collect_all(self, query: str, max_results: int = 100):
        """
        Collecte depuis TOUTES les sources
        
        Args:
            query: Requ√™te de recherche (ex: "BRCA1 breast cancer")
            max_results: Nombre maximum de r√©sultats par source
        """
        print(f"\nüìã Requ√™te: {query}")
        print(f"üéØ Max r√©sultats: {max_results}")
        
        # Extraire contexte
        genes, keywords, organism = extract_genes_and_keywords(query)
        print(f"\nüß¨ G√®nes d√©tect√©s: {genes}")
        print(f"üîë Mots-cl√©s: {keywords}")
        print(f"ü¶† Organisme: {organism}")
        
        # Si pas de g√®nes, utiliser des defaults
        if not genes:
            print("‚ö†Ô∏è Aucun g√®ne d√©tect√© - utilisation de g√®nes par d√©faut")
            if "cancer" in keywords:
                genes = ["TP53", "KRAS", "BRCA1"]
            elif "alzheimer" in keywords:
                genes = ["APP", "MAPT"]
            else:
                genes = ["TP53"]
        
        # Stats globales
        stats = {
            "query": query,
            "timestamp": datetime.now().isoformat(),
            "results": {}
        }
        
        # 1. ARTICLES
        print(f"\n{'='*70}")
        print("1Ô∏è‚É£ COLLECTE D'ARTICLES")
        print("="*70)
        n_papers = self.robot_papers.collect(query, max_results)
        stats["results"]["papers"] = n_papers
        
        # 2. IMAGES (Pathways)
        print(f"\n{'='*70}")
        print("2Ô∏è‚É£ COLLECTE D'IMAGES")
        print("="*70)
        n_images = self.robot_images.collect()
        stats["results"]["images"] = n_images
        
        # 3. EXPERIMENTS
        print(f"\n{'='*70}")
        print("3Ô∏è‚É£ COLLECTE D'EXP√âRIENCES")
        print("="*70)
        
        # Utiliser g√®nes d√©tect√©s ou defaults
        if not genes:
            genes = ["TP53"]
        
        n_experiments = self.robot_experiments.collect(
            genes=genes,
            keywords=keywords,
            organism=organism,
            max_per_gene=5  # 5 datasets par g√®ne
        )
        stats["results"]["experiments"] = n_experiments
        
        # 4. SEQUENCES
        print(f"\n{'='*70}")
        print("4Ô∏è‚É£ COLLECTE DE S√âQUENCES")
        print("="*70)
        n_sequences = self.robot_sequences.collect(
            query=query,
            organism=organism.split()[0].lower(),
            max_results=max_results // 2
        )
        stats["results"]["sequences"] = n_sequences
        
        # 5. STRUCTURES PDB
        print(f"\n{'='*70}")
        print("5Ô∏è‚É£ COLLECTE DE STRUCTURES PDB")
        print("="*70)
        n_structures = self.robot_structures.collect(
            query=query,
            max_results=max_results // 3
        )
        stats["results"]["structures"] = n_structures
        
        # 6. ALPHAFOLD
        print(f"\n{'='*70}")
        print("6Ô∏è‚É£ COLLECTE ALPHAFOLD")
        print("="*70)
        n_alphafold = self.robot_structures.collect_alphafold_from_proteins(max_results)
        stats["results"]["structures-alphafold"] = n_alphafold
        
        # R√©sum√© final
        self._print_summary(stats)
        
        # Sauvegarder les stats
        self._save_stats(stats)
    
    
    def collect_specific(self, query: str, robots: List[str], max_results: int = 100):
        """
        Collecte depuis des robots sp√©cifiques
        
        Args:
            query: Requ√™te de recherche
            robots: Liste des robots √† utiliser ['papers', 'sequences', etc.]
            max_results: Nombre maximum de r√©sultats
        """
        print(f"\nüìã Requ√™te: {query}")
        print(f"üéØ Robots: {', '.join(robots)}")
        print(f"üéØ Max r√©sultats: {max_results}")
        
        # Extraire contexte
        genes, keywords, organism = extract_genes_and_keywords(query)
        
        stats = {
            "query": query,
            "timestamp": datetime.now().isoformat(),
            "robots": robots,
            "results": {}
        }
        
        # Ex√©cuter les robots demand√©s
        if "papers" in robots:
            print(f"\n{'='*70}")
            print("üìÑ COLLECTE D'ARTICLES")
            print("="*70)
            n = self.robot_papers.collect(query, max_results)
            stats["results"]["papers"] = n
        
        if "images" in robots:
            print(f"\n{'='*70}")
            print("üñºÔ∏è COLLECTE D'IMAGES")
            print("="*70)
            n = self.robot_images.collect()
            stats["results"]["images"] = n
        
        if "experiments" in robots:
            print(f"\n{'='*70}")
            print("üß™ COLLECTE D'EXP√âRIENCES")
            print("="*70)
            if not genes:
                genes = ["TP53"]  # G√®ne par d√©faut
            n = self.robot_experiments.collect(genes, keywords, organism, max_per_gene=5)
            stats["results"]["experiments"] = n
        
        if "sequences" in robots:
            print(f"\n{'='*70}")
            print("üß¨ COLLECTE DE S√âQUENCES")
            print("="*70)
            n = self.robot_sequences.collect(query, organism.split()[0].lower(), max_results // 2)
            stats["results"]["sequences"] = n
        
        if "structures" in robots:
            print(f"\n{'='*70}")
            print("üî¨ COLLECTE DE STRUCTURES PDB")
            print("="*70)
            n = self.robot_structures.collect(query, max_results // 3)
            stats["results"]["structures"] = n
        
        if "structures-alphafold" in robots:
            print(f"\n{'='*70}")
            print("ü§ñ COLLECTE ALPHAFOLD")
            print("="*70)
            n = self.robot_structures.collect_alphafold_from_proteins(max_results)
            stats["results"]["structures-alphafold"] = n
        
        # R√©sum√©
        self._print_summary(stats)
        self._save_stats(stats)
    
    
    def _print_summary(self, stats: dict):
        """Affiche le r√©sum√© de la collecte"""
        print(f"\n{'='*70}")
        print("üìä R√âSUM√â DE LA COLLECTE")
        print("="*70)
        print(f"\nüîç Requ√™te: {stats['query']}")
        print(f"‚è∞ Date: {stats['timestamp']}")
        print(f"\nüìà R√©sultats:")
        
        total = 0
        for source, count in stats["results"].items():
            print(f"   ‚Ä¢ {source:15}: {count:4} nouveaux")
            total += count
        
        print(f"\n‚úÖ Total: {total} nouvelles entr√©es")
        print("="*70)
    
    
    def _save_stats(self, stats: dict):
        """Sauvegarde les statistiques de collecte"""
        stats_file = os.path.join(DATA_DIR, "collection_stats.json")
        
        # Charger stats existantes
        all_stats = []
        if os.path.exists(stats_file):
            with open(stats_file, 'r', encoding='utf-8') as f:
                all_stats = json.load(f)
        
        # Ajouter nouvelles stats
        all_stats.append(stats)
        
        # Sauvegarder
        with open(stats_file, 'w', encoding='utf-8') as f:
            json.dump(all_stats, f, indent=2, ensure_ascii=False)
        
        print(f"\nüíæ Statistiques sauvegard√©es: {stats_file}")


# ============================================================================
# MAIN
# ============================================================================

def main():
    parser = argparse.ArgumentParser(
        description="ü§ñ Data Collector - Syst√®me de collecte automatique",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
Exemples:
  python data_collect.py --query "BRCA1 breast cancer" --all
  python data_collect.py --query "TP53 p53 cancer" --papers --sequences
  python data_collect.py --query "Alzheimer tau protein" --experiments --max 50
        """
    )
    
    # Arguments
    parser.add_argument(
        "--query",
        type=str,
        required=True,
        help="Requ√™te de recherche (ex: 'BRCA1 breast cancer')"
    )
    
    parser.add_argument(
        "--max",
        type=int,
        default=100,
        help="Nombre maximum de r√©sultats par source (d√©faut: 100)"
    )
    
    # Robots
    parser.add_argument("--all", action="store_true", help="Utiliser tous les robots")
    parser.add_argument("--papers", action="store_true", help="Collecter des articles")
    parser.add_argument("--images", action="store_true", help="Collecter des images")
    parser.add_argument("--experiments", action="store_true", help="Collecter des exp√©riences")
    parser.add_argument("--sequences", action="store_true", help="Collecter des s√©quences")
    parser.add_argument("--structures", action="store_true", help="Collecter des structures PDB")
    parser.add_argument("--structures-alphafold", action="store_true", help="Collecter AlphaFold depuis proteins.json")
    
    args = parser.parse_args()
    
    # Cr√©er le collecteur
    collector = DataCollector()
    
    # D√©terminer les robots √† utiliser
    if args.all:
        collector.collect_all(args.query, args.max)
    else:
        robots = []
        if args.papers:
            robots.append("papers")
        if args.images:
            robots.append("images")
        if args.experiments:
            robots.append("experiments")
        if args.sequences:
            robots.append("sequences")
        if args.structures:
            robots.append("structures")
        if args.structures_alphafold:
            robots.append("structures-alphafold")
        
        if not robots:
            print("‚ùå Aucun robot s√©lectionn√©. Utilisez --all ou sp√©cifiez des robots.")
            print("   Exemple: python data_collect.py --query 'cancer' --papers --sequences")
            return
        
        collector.collect_specific(args.query, robots, args.max)


if __name__ == "__main__":
    main()
